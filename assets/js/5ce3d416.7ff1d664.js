"use strict";(self.webpackChunkdocusaurus=self.webpackChunkdocusaurus||[]).push([[162],{6009:(n,e,a)=>{a.r(e),a.d(e,{assets:()=>l,contentTitle:()=>o,default:()=>c,frontMatter:()=>s,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"module3/sim_to_real_transfer","title":"Sim-to-Real Transfer Techniques","description":"Introduction","source":"@site/docs/module3/sim_to_real_transfer.md","sourceDirName":"module3","slug":"/module3/sim_to_real_transfer","permalink":"/humanoid-robotics-book/docs/module3/sim_to_real_transfer","draft":false,"unlisted":false,"editUrl":"https://github.com/Amnaahmed798/humanoid-robotics-book/edit/main/docs/module3/sim_to_real_transfer.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Reinforcement Learning for Robot Control","permalink":"/humanoid-robotics-book/docs/module3/reinforcement_learning"},"next":{"title":"Synthetic Data Generation and Photorealistic Simulation","permalink":"/humanoid-robotics-book/docs/module3/synthetic_data"}}');var t=a(4848),r=a(8453);const s={},o="Sim-to-Real Transfer Techniques",l={},d=[{value:"Introduction",id:"introduction",level:2},{value:"The Sim-to-Real Gap",id:"the-sim-to-real-gap",level:2},{value:"Sources of Discrepancy",id:"sources-of-discrepancy",level:3},{value:"The Reality Gap Problem",id:"the-reality-gap-problem",level:3},{value:"Domain Randomization",id:"domain-randomization",level:2},{value:"Concept and Implementation",id:"concept-and-implementation",level:3},{value:"Advanced Domain Randomization",id:"advanced-domain-randomization",level:3},{value:"System Identification and System Modeling",id:"system-identification-and-system-modeling",level:2},{value:"Physics Parameter Estimation",id:"physics-parameter-estimation",level:3},{value:"Domain Adaptation Techniques",id:"domain-adaptation-techniques",level:2},{value:"Visual Domain Adaptation",id:"visual-domain-adaptation",level:3},{value:"Robust Control Design",id:"robust-control-design",level:2},{value:"Robust Policy Training",id:"robust-policy-training",level:3},{value:"Fine-Tuning on Real Data",id:"fine-tuning-on-real-data",level:2},{value:"Real-to-Sim Transfer Learning",id:"real-to-sim-transfer-learning",level:3},{value:"Calibration and Validation",id:"calibration-and-validation",level:2},{value:"Systematic Validation Approach",id:"systematic-validation-approach",level:3},{value:"Best Practices for Sim-to-Real Transfer",id:"best-practices-for-sim-to-real-transfer",level:2},{value:"Planning and Design Phase",id:"planning-and-design-phase",level:3},{value:"Training Phase",id:"training-phase",level:3},{value:"Deployment Phase",id:"deployment-phase",level:3},{value:"Continuous Improvement",id:"continuous-improvement",level:3}];function m(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"sim-to-real-transfer-techniques",children:"Sim-to-Real Transfer Techniques"})}),"\n",(0,t.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsx)(e.p,{children:"Sim-to-real transfer, also known as domain transfer, is the process of taking policies or models trained in simulation and successfully deploying them on real robots. This is a critical challenge in robotics because, while simulation offers safe, fast, and cost-effective training, real-world environments have physical properties, sensor noise, and dynamics that differ from their simulated counterparts. This chapter explores various techniques to bridge the sim-to-real gap."}),"\n",(0,t.jsx)(e.h2,{id:"the-sim-to-real-gap",children:"The Sim-to-Real Gap"}),"\n",(0,t.jsx)(e.h3,{id:"sources-of-discrepancy",children:"Sources of Discrepancy"}),"\n",(0,t.jsx)(e.p,{children:"The sim-to-real gap arises from several sources:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Visual Differences"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Lighting conditions"}),"\n",(0,t.jsx)(e.li,{children:"Texture and material properties"}),"\n",(0,t.jsx)(e.li,{children:"Camera noise and artifacts"}),"\n",(0,t.jsx)(e.li,{children:"Resolution and color representation"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Physical Differences"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Friction coefficients"}),"\n",(0,t.jsx)(e.li,{children:"Mass and inertia properties"}),"\n",(0,t.jsx)(e.li,{children:"Actuator dynamics"}),"\n",(0,t.jsx)(e.li,{children:"Compliance and flexibility"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Sensor Differences"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Noise characteristics"}),"\n",(0,t.jsx)(e.li,{children:"Latency and timing"}),"\n",(0,t.jsx)(e.li,{children:"Calibration differences"}),"\n",(0,t.jsx)(e.li,{children:"Field of view variations"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.strong,{children:"Environmental Differences"}),":"]}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Unmodeled dynamics"}),"\n",(0,t.jsx)(e.li,{children:"Air resistance and fluid effects"}),"\n",(0,t.jsx)(e.li,{children:"Temperature variations"}),"\n",(0,t.jsx)(e.li,{children:"Wear and tear effects"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"the-reality-gap-problem",children:"The Reality Gap Problem"}),"\n",(0,t.jsx)(e.p,{children:"The reality gap can cause policies that work perfectly in simulation to fail completely on real robots. This is particularly problematic for learning-based approaches where the agent has learned specific patterns that don't generalize to the real world."}),"\n",(0,t.jsx)(e.h2,{id:"domain-randomization",children:"Domain Randomization"}),"\n",(0,t.jsx)(e.h3,{id:"concept-and-implementation",children:"Concept and Implementation"}),"\n",(0,t.jsx)(e.p,{children:"Domain randomization is a technique that aims to make policies robust to sim-to-real differences by training on a wide variety of randomized environments:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import numpy as np\nimport random\n\nclass DomainRandomizer:\n    \"\"\"\n    Implements domain randomization for sim-to-real transfer.\n    \"\"\"\n\n    def __init__(self):\n        self.parameters = {\n            # Visual parameters\n            'lighting_intensity': (0.5, 2.0),\n            'lighting_color_temp': (3000, 8000),\n            'camera_noise_std': (0.0, 0.05),\n            'material_roughness': (0.1, 0.9),\n            'material_metallic': (0.0, 1.0),\n\n            # Physical parameters\n            'friction_coeff': (0.1, 0.9),\n            'restitution': (0.0, 0.5),\n            'object_mass_multiplier': (0.8, 1.2),\n            'gravity_z': (-11.0, -9.0),\n\n            # Dynamical parameters\n            'actuator_delay': (0.0, 0.02),\n            'sensor_latency': (0.0, 0.01),\n            'joint_friction': (0.0, 0.1),\n        }\n\n    def randomize_environment(self):\n        \"\"\"\n        Randomize environment parameters according to defined ranges.\n        \"\"\"\n        randomized_values = {}\n\n        for param_name, (min_val, max_val) in self.parameters.items():\n            if 'color' in param_name:\n                # For color temperature, use integer values\n                randomized_values[param_name] = random.randint(int(min_val), int(max_val))\n            elif 'delay' in param_name or 'latency' in param_name:\n                # For timing parameters, use smaller steps\n                randomized_values[param_name] = random.uniform(min_val, max_val)\n            else:\n                # For most parameters, use continuous uniform distribution\n                randomized_values[param_name] = random.uniform(min_val, max_val)\n\n        return randomized_values\n\n    def apply_randomization(self, sim_env, randomization_values):\n        \"\"\"\n        Apply the randomization values to the simulation environment.\n        \"\"\"\n        # Apply lighting changes\n        sim_env.set_lighting_intensity(randomization_values['lighting_intensity'])\n        sim_env.set_lighting_color_temperature(randomization_values['lighting_color_temp'])\n\n        # Apply material properties\n        sim_env.set_material_roughness(randomization_values['material_roughness'])\n        sim_env.set_material_metallic(randomization_values['material_metallic'])\n\n        # Apply physical properties\n        sim_env.set_friction_coefficient(randomization_values['friction_coeff'])\n        sim_env.set_restitution_coefficient(randomization_values['restitution'])\n        sim_env.set_gravity_z(randomization_values['gravity_z'])\n\n        # Apply sensor noise\n        sim_env.set_camera_noise_std(randomization_values['camera_noise_std'])\n\n        # Apply dynamical parameters\n        sim_env.set_actuator_delay(randomization_values['actuator_delay'])\n        sim_env.set_sensor_latency(randomization_values['sensor_latency'])\n        sim_env.set_joint_friction(randomization_values['joint_friction'])\n\n    def get_realistic_range(self, real_value, variation_percent=0.2):\n        \"\"\"\n        Get a range around a real-world value for randomization.\n        \"\"\"\n        variation = real_value * variation_percent\n        min_val = max(0, real_value - variation)  # Ensure non-negative for some parameters\n        max_val = real_value + variation\n        return (min_val, max_val)\n"})}),"\n",(0,t.jsx)(e.h3,{id:"advanced-domain-randomization",children:"Advanced Domain Randomization"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"class AdvancedDomainRandomizer(DomainRandomizer):\n    \"\"\"\n    Advanced domain randomization with correlated parameter changes.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n        # Correlation rules: when one parameter changes, others change accordingly\n        self.correlations = {\n            'high_friction': ['high_restitution', 'high_joint_friction'],\n            'low_lighting': ['high_camera_noise'],\n            'high_mass': ['high_actuator_delay']\n        }\n\n        # Temporal consistency for slowly changing parameters\n        self.temporal_params = {\n            'temperature': {'current': 25.0, 'rate': 0.1, 'range': (15.0, 35.0)},\n            'humidity': {'current': 50.0, 'rate': 0.05, 'range': (30.0, 80.0)}\n        }\n\n    def randomize_with_correlations(self, step_count):\n        \"\"\"\n        Randomize parameters with correlations and temporal consistency.\n        \"\"\"\n        randomized_values = {}\n\n        # Randomize base parameters\n        for param_name, (min_val, max_val) in self.parameters.items():\n            if 'color' in param_name:\n                randomized_values[param_name] = random.randint(int(min_val), int(max_val))\n            else:\n                randomized_values[param_name] = random.uniform(min_val, max_val)\n\n        # Apply correlations\n        if randomized_values['friction_coeff'] > 0.7:  # High friction\n            randomized_values['restitution'] = max(\n                randomized_values['restitution'],\n                np.random.uniform(0.3, 0.5)\n            )\n            randomized_values['joint_friction'] = max(\n                randomized_values['joint_friction'],\n                np.random.uniform(0.05, 0.1)\n            )\n\n        if randomized_values['lighting_intensity'] < 0.8:  # Low lighting\n            randomized_values['camera_noise_std'] = max(\n                randomized_values['camera_noise_std'],\n                np.random.uniform(0.03, 0.05)\n            )\n\n        # Update temporal parameters gradually\n        for param_name, param_info in self.temporal_params.items():\n            # Move parameter value gradually\n            direction = random.choice([-1, 1])\n            change = direction * param_info['rate'] * random.random()\n            new_value = param_info['current'] + change\n\n            # Keep within bounds\n            new_value = max(param_info['range'][0], min(param_info['range'][1], new_value))\n            param_info['current'] = new_value\n\n            randomized_values[f\"{param_name}_value\"] = new_value\n\n        return randomized_values\n"})}),"\n",(0,t.jsx)(e.h2,{id:"system-identification-and-system-modeling",children:"System Identification and System Modeling"}),"\n",(0,t.jsx)(e.h3,{id:"physics-parameter-estimation",children:"Physics Parameter Estimation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import scipy.optimize as opt\nimport numpy as np\n\nclass SystemIdentifier:\n    """\n    System identification for improving simulation accuracy.\n    """\n\n    def __init__(self, robot_model):\n        self.robot_model = robot_model\n        self.sim_params = {}\n        self.real_params = {}\n\n    def collect_system_data(self, robot, input_sequence):\n        """\n        Collect input-output data from real robot for system identification.\n        """\n        real_states = []\n        real_outputs = []\n\n        # Execute input sequence on real robot\n        for input_cmd in input_sequence:\n            # Apply input to real robot\n            robot.apply_command(input_cmd)\n\n            # Wait for system to settle\n            robot.wait(0.1)\n\n            # Record state and output\n            state = robot.get_state()\n            output = robot.get_sensor_data()\n\n            real_states.append(state)\n            real_outputs.append(output)\n\n        return real_states, real_outputs\n\n    def simulate_with_params(self, params, input_sequence):\n        """\n        Simulate the system with given parameters.\n        """\n        # Update simulation with new parameters\n        self.update_simulation_params(params)\n\n        sim_states = []\n        sim_outputs = []\n\n        # Run same input sequence in simulation\n        for input_cmd in input_sequence:\n            # Apply input to simulation\n            self.robot_model.apply_command(input_cmd)\n\n            # Wait for system to settle\n            self.robot_model.wait(0.1)\n\n            # Record state and output\n            state = self.robot_model.get_state()\n            output = self.robot_model.get_sensor_data()\n\n            sim_states.append(state)\n            sim_outputs.append(output)\n\n        return sim_states, sim_outputs\n\n    def parameter_estimation_objective(self, params, input_sequence, real_data):\n        """\n        Objective function for parameter estimation.\n        """\n        real_states, real_outputs = real_data\n        sim_states, sim_outputs = self.simulate_with_params(params, input_sequence)\n\n        # Calculate error between real and simulated data\n        error = 0\n        for i in range(len(real_states)):\n            # State error\n            state_error = np.linalg.norm(\n                np.array(real_states[i]) - np.array(sim_states[i])\n            )\n\n            # Output error\n            output_error = np.linalg.norm(\n                np.array(real_outputs[i]) - np.array(sim_outputs[i])\n            )\n\n            error += state_error + output_error\n\n        return error\n\n    def identify_system_parameters(self, input_sequence, real_data):\n        """\n        Identify system parameters by minimizing simulation error.\n        """\n        # Initial parameter guess (from CAD model or nominal values)\n        initial_params = self.get_nominal_parameters()\n\n        # Optimize parameters to minimize error\n        result = opt.minimize(\n            self.parameter_estimation_objective,\n            initial_params,\n            args=(input_sequence, real_data),\n            method=\'L-BFGS-B\'\n        )\n\n        # Update simulation with identified parameters\n        self.update_simulation_params(result.x)\n\n        return result.x\n\n    def get_nominal_parameters(self):\n        """\n        Get initial parameter estimates.\n        """\n        # This would come from CAD models, datasheets, etc.\n        return np.array([1.0, 0.1, 0.5, 9.81])  # mass, friction, damping, gravity\n\n    def update_simulation_params(self, params):\n        """\n        Update simulation with new parameters.\n        """\n        # Update the simulation model with identified parameters\n        # This is specific to the simulation environment being used\n        pass\n'})}),"\n",(0,t.jsx)(e.h2,{id:"domain-adaptation-techniques",children:"Domain Adaptation Techniques"}),"\n",(0,t.jsx)(e.h3,{id:"visual-domain-adaptation",children:"Visual Domain Adaptation"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms\nimport numpy as np\n\nclass VisualDomainAdapter:\n    """\n    Visual domain adaptation for camera-based perception.\n    """\n\n    def __init__(self, device=\'cuda\'):\n        self.device = device\n        self.sim2real_model = self.build_adaptation_model()\n        self.real2sim_model = self.build_adaptation_model()\n\n    def build_adaptation_model(self):\n        """\n        Build a model for domain adaptation (e.g., image translation).\n        """\n        # This could be an image-to-image translation network like CycleGAN\n        model = nn.Sequential(\n            # Encoder\n            nn.Conv2d(3, 64, 4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n            nn.ReLU(),\n\n            # Decoder\n            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1),\n            nn.Tanh()\n        )\n\n        return model.to(self.device)\n\n    def adapt_visual_data(self, sim_image, direction=\'sim2real\'):\n        """\n        Adapt visual data from one domain to another.\n        """\n        if direction == \'sim2real\':\n            model = self.sim2real_model\n        else:\n            model = self.real2sim_model\n\n        # Preprocess image\n        sim_tensor = self.preprocess_image(sim_image).to(self.device)\n\n        # Apply domain adaptation\n        adapted_tensor = model(sim_tensor)\n\n        # Postprocess\n        adapted_image = self.postprocess_image(adapted_tensor)\n\n        return adapted_image\n\n    def preprocess_image(self, image):\n        """\n        Preprocess image for domain adaptation network.\n        """\n        transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n        ])\n        return transform(image).unsqueeze(0)\n\n    def postprocess_image(self, tensor):\n        """\n        Postprocess tensor back to image format.\n        """\n        # Denormalize\n        tensor = tensor.squeeze(0)\n        tensor = tensor * 0.5 + 0.5\n        tensor = torch.clamp(tensor, 0, 1)\n\n        # Convert to numpy\n        image = tensor.detach().cpu().numpy().transpose(1, 2, 0)\n        return (image * 255).astype(np.uint8)\n\n    def train_adaptation_model(self, sim_data_loader, real_data_loader, epochs=100):\n        """\n        Train the domain adaptation model using adversarial training.\n        """\n        # This would implement CycleGAN or similar domain adaptation approach\n        # For brevity, we\'ll outline the key components:\n\n        # 1. Generator losses (for image translation)\n        # 2. Discriminator losses (to distinguish domains)\n        # 3. Cycle consistency losses\n        # 4. Identity losses\n\n        optimizer_G = optim.Adam(\n            list(self.sim2real_model.parameters()) +\n            list(self.real2sim_model.parameters()),\n            lr=0.0002, betas=(0.5, 0.999)\n        )\n\n        optimizer_D = optim.Adam(\n            list(self.sim2real_model.parameters()) +\n            list(self.real2sim_model.parameters()),\n            lr=0.0002, betas=(0.5, 0.999)\n        )\n\n        # Training loop would go here\n        # This is a simplified representation\n        pass\n'})}),"\n",(0,t.jsx)(e.h2,{id:"robust-control-design",children:"Robust Control Design"}),"\n",(0,t.jsx)(e.h3,{id:"robust-policy-training",children:"Robust Policy Training"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'class RobustPolicyTrainer:\n    """\n    Trainer for robust policies that can handle sim-to-real differences.\n    """\n\n    def __init__(self, base_policy, env_model):\n        self.base_policy = base_policy\n        self.env_model = env_model\n        self.robustness_metrics = []\n\n    def train_with_disturbances(self, episodes=1000):\n        """\n        Train policy with injected disturbances to improve robustness.\n        """\n        for episode in range(episodes):\n            # Add random disturbances to simulation\n            disturbance = self.generate_disturbance()\n            self.env_model.add_disturbance(disturbance)\n\n            # Train on disturbed environment\n            episode_reward = self.run_episode()\n\n            # Remove disturbance for next iteration\n            self.env_model.remove_disturbance()\n\n            # Record robustness metrics\n            self.robustness_metrics.append({\n                \'episode\': episode,\n                \'disturbance_magnitude\': np.linalg.norm(disturbance),\n                \'episode_reward\': episode_reward\n            })\n\n    def generate_disturbance(self):\n        """\n        Generate random disturbances to improve robustness.\n        """\n        disturbance_types = [\n            self.random_force_disturbance,\n            self.random_sensor_noise,\n            self.random_dynamics_change,\n            self.random_external_perturbation\n        ]\n\n        # Randomly select disturbance type and parameters\n        disturbance_fn = random.choice(disturbance_types)\n        return disturbance_fn()\n\n    def random_force_disturbance(self):\n        """\n        Generate random force disturbances.\n        """\n        force_magnitude = np.random.uniform(0, 10)  # Newtons\n        force_direction = np.random.uniform(-1, 1, 3)\n        force_direction = force_direction / np.linalg.norm(force_direction)\n\n        return force_magnitude * force_direction\n\n    def random_sensor_noise(self):\n        """\n        Generate random sensor noise characteristics.\n        """\n        noise_std = np.random.uniform(0, 0.1)\n        bias = np.random.uniform(-0.05, 0.05)\n\n        return {\'noise_std\': noise_std, \'bias\': bias}\n\n    def random_dynamics_change(self):\n        """\n        Generate random dynamics parameter changes.\n        """\n        friction_change = np.random.uniform(-0.2, 0.2)\n        mass_change = np.random.uniform(-0.1, 0.1)\n\n        return {\'friction_change\': friction_change, \'mass_change\': mass_change}\n\n    def random_external_perturbation(self):\n        """\n        Generate random external perturbations.\n        """\n        perturbation_force = np.random.uniform(-5, 5, 3)\n        perturbation_duration = np.random.uniform(0.1, 0.5)\n\n        return {\n            \'force\': perturbation_force,\n            \'duration\': perturbation_duration\n        }\n\n    def adversarial_training(self, adversary_steps=5):\n        """\n        Train with adversarial perturbations to find worst-case scenarios.\n        """\n        for step in range(adversary_steps):\n            # Train adversary to find worst-case disturbances\n            worst_disturbance = self.find_worst_disturbance()\n\n            # Train policy to handle worst-case scenario\n            self.train_on_disturbance(worst_disturbance)\n\n    def find_worst_disturbance(self):\n        """\n        Find the disturbance that minimizes policy performance.\n        """\n        # This would use optimization techniques to find worst-case disturbance\n        # For example, gradient-based optimization on disturbance parameters\n        pass\n\n    def evaluate_robustness(self, test_disturbances):\n        """\n        Evaluate policy robustness against various disturbances.\n        """\n        robustness_scores = []\n\n        for disturbance in test_disturbances:\n            # Apply disturbance\n            self.env_model.add_disturbance(disturbance)\n\n            # Test policy performance\n            test_reward = self.test_policy_performance()\n            robustness_scores.append(test_reward)\n\n            # Remove disturbance\n            self.env_model.remove_disturbance()\n\n        return robustness_scores\n'})}),"\n",(0,t.jsx)(e.h2,{id:"fine-tuning-on-real-data",children:"Fine-Tuning on Real Data"}),"\n",(0,t.jsx)(e.h3,{id:"real-to-sim-transfer-learning",children:"Real-to-Sim Transfer Learning"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass RealToSimTransferLearner:\n    """\n    Transfer learning approach to adapt sim-trained models to real data.\n    """\n\n    def __init__(self, pretrained_model_path, learning_rate=1e-4):\n        self.model = self.load_pretrained_model(pretrained_model_path)\n        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n        self.criterion = nn.MSELoss()\n\n    def load_pretrained_model(self, path):\n        """\n        Load a model pre-trained in simulation.\n        """\n        # This assumes a PyTorch model\n        model = torch.load(path)\n        return model\n\n    def fine_tune_on_real_data(self, real_data_loader, epochs=10):\n        """\n        Fine-tune the model on real-world data.\n        """\n        self.model.train()\n\n        for epoch in range(epochs):\n            epoch_loss = 0\n            num_batches = 0\n\n            for batch_idx, (real_inputs, real_targets) in enumerate(real_data_loader):\n                # Move data to device\n                real_inputs = real_inputs.to(self.model.device)\n                real_targets = real_targets.to(self.model.device)\n\n                # Forward pass\n                outputs = self.model(real_inputs)\n                loss = self.criterion(outputs, real_targets)\n\n                # Backward pass\n                self.optimizer.zero_grad()\n                loss.backward()\n                self.optimizer.step()\n\n                epoch_loss += loss.item()\n                num_batches += 1\n\n            avg_loss = epoch_loss / num_batches\n            print(f"Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}")\n\n    def gradual_domain_transfer(self, sim_loader, real_loader, epochs=20):\n        """\n        Gradually transfer from simulation to real data.\n        """\n        total_steps = epochs * len(sim_loader)\n        current_step = 0\n\n        for epoch in range(epochs):\n            # Calculate interpolation factor\n            alpha = min(1.0, current_step / (total_steps / 2))  # Reach 1.0 halfway\n\n            # Interpolate between sim and real data\n            for sim_batch, real_batch in zip(sim_loader, real_loader):\n                # Weight real data more as training progresses\n                real_weight = alpha\n                sim_weight = 1 - alpha\n\n                # Train on combined batch\n                self.train_step(sim_batch, real_batch, sim_weight, real_weight)\n\n                current_step += 1\n\n    def train_step(self, sim_batch, real_batch, sim_weight, real_weight):\n        """\n        Single training step with weighted sim and real data.\n        """\n        # Process simulation data\n        if sim_weight > 0:\n            sim_inputs, sim_targets = sim_batch\n            sim_inputs = sim_inputs.to(self.model.device)\n            sim_targets = sim_targets.to(self.model.device)\n\n            sim_outputs = self.model(sim_inputs)\n            sim_loss = self.criterion(sim_outputs, sim_targets) * sim_weight\n        else:\n            sim_loss = 0\n\n        # Process real data\n        if real_weight > 0:\n            real_inputs, real_targets = real_batch\n            real_inputs = real_inputs.to(self.model.device)\n            real_targets = real_targets.to(self.model.device)\n\n            real_outputs = self.model(real_inputs)\n            real_loss = self.criterion(real_outputs, real_targets) * real_weight\n        else:\n            real_loss = 0\n\n        # Combined loss\n        total_loss = sim_loss + real_loss\n\n        # Backward pass\n        self.optimizer.zero_grad()\n        total_loss.backward()\n        self.optimizer.step()\n\n    def test_on_real_robot(self, real_robot_interface):\n        """\n        Test the fine-tuned model on a real robot.\n        """\n        self.model.eval()\n\n        with torch.no_grad():\n            # Reset robot to initial state\n            real_robot_interface.reset()\n\n            total_reward = 0\n            done = False\n\n            while not done:\n                # Get observation from real robot\n                obs = real_robot_interface.get_observation()\n                obs_tensor = torch.FloatTensor(obs).unsqueeze(0).to(self.model.device)\n\n                # Get action from model\n                action_tensor = self.model(obs_tensor)\n                action = action_tensor.cpu().numpy().flatten()\n\n                # Execute action\n                obs, reward, done, info = real_robot_interface.step(action)\n                total_reward += reward\n\n                print(f"Action: {action}, Reward: {reward}, Cumulative: {total_reward}")\n\n        return total_reward\n'})}),"\n",(0,t.jsx)(e.h2,{id:"calibration-and-validation",children:"Calibration and Validation"}),"\n",(0,t.jsx)(e.h3,{id:"systematic-validation-approach",children:"Systematic Validation Approach"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'class TransferValidator:\n    """\n    Systematic validation of sim-to-real transfer performance.\n    """\n\n    def __init__(self, sim_env, real_robot):\n        self.sim_env = sim_env\n        self.real_robot = real_robot\n        self.validation_metrics = {}\n\n    def validate_behavior_similarity(self):\n        """\n        Validate that robot behaviors are similar in sim and real.\n        """\n        behaviors_to_test = [\n            \'reach_target\',\n            \'avoid_obstacle\',\n            \'grasp_object\',\n            \'follow_trajectory\'\n        ]\n\n        similarity_scores = {}\n\n        for behavior in behaviors_to_test:\n            sim_trajectory = self.test_behavior_in_sim(behavior)\n            real_trajectory = self.test_behavior_on_real(behavior)\n\n            # Calculate similarity metric\n            similarity = self.calculate_trajectory_similarity(\n                sim_trajectory, real_trajectory\n            )\n\n            similarity_scores[behavior] = similarity\n\n        return similarity_scores\n\n    def test_behavior_in_sim(self, behavior_name):\n        """\n        Test a specific behavior in simulation.\n        """\n        # Reset environment\n        self.sim_env.reset()\n\n        # Execute behavior-specific policy\n        trajectory = []\n        done = False\n\n        while not done:\n            # Get state\n            state = self.sim_env.get_state()\n            trajectory.append(state)\n\n            # Get action based on behavior\n            action = self.get_behavior_action(behavior_name, state)\n\n            # Step environment\n            obs, reward, done, info = self.sim_env.step(action)\n\n        return trajectory\n\n    def test_behavior_on_real(self, behavior_name):\n        """\n        Test a specific behavior on real robot.\n        """\n        # Reset real robot\n        self.real_robot.reset()\n\n        # Execute behavior\n        trajectory = []\n        done = False\n\n        while not done:\n            # Get state from real robot\n            state = self.real_robot.get_state()\n            trajectory.append(state)\n\n            # Get action based on behavior\n            action = self.get_behavior_action(behavior_name, state)\n\n            # Execute on real robot\n            obs, reward, done, info = self.real_robot.step(action)\n\n        return trajectory\n\n    def calculate_trajectory_similarity(self, sim_traj, real_traj):\n        """\n        Calculate similarity between simulation and real trajectories.\n        """\n        # Ensure trajectories are same length (pad shorter one)\n        max_len = max(len(sim_traj), len(real_traj))\n\n        if len(sim_traj) < max_len:\n            # Pad with last state\n            sim_traj.extend([sim_traj[-1]] * (max_len - len(sim_traj)))\n\n        if len(real_traj) < max_len:\n            # Pad with last state\n            real_traj.extend([real_traj[-1]] * (max_len - len(real_traj)))\n\n        # Calculate average distance between corresponding states\n        total_distance = 0\n        for sim_state, real_state in zip(sim_traj, real_traj):\n            distance = np.linalg.norm(\n                np.array(sim_state) - np.array(real_state)\n            )\n            total_distance += distance\n\n        avg_distance = total_distance / max_len\n\n        # Convert to similarity score (0-1, where 1 is perfect similarity)\n        max_possible_distance = 10.0  # Adjust based on your state space\n        similarity = max(0, 1 - (avg_distance / max_possible_distance))\n\n        return similarity\n\n    def get_behavior_action(self, behavior_name, state):\n        """\n        Get action for a specific behavior.\n        """\n        # This would use behavior-specific policies or controllers\n        if behavior_name == \'reach_target\':\n            return self.reach_target_action(state)\n        elif behavior_name == \'avoid_obstacle\':\n            return self.avoid_obstacle_action(state)\n        elif behavior_name == \'grasp_object\':\n            return self.grasp_action(state)\n        elif behavior_name == \'follow_trajectory\':\n            return self.follow_trajectory_action(state)\n        else:\n            # Default random action\n            return np.random.uniform(-1, 1, size=7)  # 7-DOF example\n\n    def validate_safety_properties(self):\n        """\n        Validate that safety properties hold in real world.\n        """\n        safety_checks = [\n            self.check_joint_limits,\n            self.check_collision_avoidance,\n            self.check_velocity_bounds,\n            self.check_force_limits\n        ]\n\n        safety_results = {}\n\n        for check_fn in safety_checks:\n            safety_results[check_fn.__name__] = check_fn()\n\n        return safety_results\n\n    def check_joint_limits(self):\n        """\n        Check if joint limits are respected.\n        """\n        # Monitor joint positions during operation\n        joint_pos = self.real_robot.get_joint_positions()\n        joint_limits = self.real_robot.get_joint_limits()\n\n        for pos, limits in zip(joint_pos, joint_limits):\n            if pos < limits[0] or pos > limits[1]:\n                return False  # Joint limit violation\n\n        return True\n\n    def check_collision_avoidance(self):\n        """\n        Check if collision avoidance works.\n        """\n        # This would involve checking distance to obstacles\n        # and ensuring robot doesn\'t collide\n        pass\n\n    def generate_transfer_report(self):\n        """\n        Generate a comprehensive transfer validation report.\n        """\n        report = {\n            \'behavior_similarity\': self.validate_behavior_similarity(),\n            \'safety_validation\': self.validate_safety_properties(),\n            \'transfer_success_rate\': self.calculate_success_rate(),\n            \'performance_metrics\': self.collect_performance_metrics(),\n            \'recommendations\': self.generate_recommendations()\n        }\n\n        return report\n\n    def calculate_success_rate(self):\n        """\n        Calculate the success rate of transfer.\n        """\n        # Run multiple trials and calculate success rate\n        num_trials = 50\n        num_successes = 0\n\n        for trial in range(num_trials):\n            if self.run_transfer_trial():\n                num_successes += 1\n\n        success_rate = num_successes / num_trials\n        return success_rate\n\n    def run_transfer_trial(self):\n        """\n        Run a single transfer trial.\n        """\n        # Reset robot\n        self.real_robot.reset()\n\n        # Execute policy\n        done = False\n        success = False\n\n        while not done:\n            state = self.real_robot.get_state()\n            action = self.execute_trained_policy(state)\n            obs, reward, done, info = self.real_robot.step(action)\n\n            # Check for success condition\n            if self.check_success_condition(obs):\n                success = True\n                break\n\n        return success\n\n    def execute_trained_policy(self, state):\n        """\n        Execute the trained policy on real robot.\n        """\n        # This would interface with your trained RL model\n        pass\n\n    def check_success_condition(self, obs):\n        """\n        Check if the task was completed successfully.\n        """\n        # This depends on the specific task\n        pass\n\n    def generate_recommendations(self):\n        """\n        Generate recommendations for improving transfer.\n        """\n        recommendations = []\n\n        # Analyze validation results and generate suggestions\n        similarity_scores = self.validate_behavior_similarity()\n\n        for behavior, score in similarity_scores.items():\n            if score < 0.7:  # Below 70% similarity\n                recommendations.append(\n                    f"Improve {behavior} transfer - current similarity: {score:.2f}"\n                )\n\n        safety_results = self.validate_safety_properties()\n        for check, passed in safety_results.items():\n            if not passed:\n                recommendations.append(f"Fix safety issue in {check}")\n\n        return recommendations\n'})}),"\n",(0,t.jsx)(e.h2,{id:"best-practices-for-sim-to-real-transfer",children:"Best Practices for Sim-to-Real Transfer"}),"\n",(0,t.jsx)(e.h3,{id:"planning-and-design-phase",children:"Planning and Design Phase"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Model Fidelity"}),": Balance simulation accuracy with computational efficiency"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Sensor Modeling"}),": Accurately model sensor characteristics and noise"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Actuator Dynamics"}),": Include realistic actuator response times and limitations"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Environmental Factors"}),": Consider lighting, temperature, and other environmental variables"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"training-phase",children:"Training Phase"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Extensive Randomization"}),": Apply domain randomization across all possible parameters"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Robust Reward Design"}),": Create rewards that don't depend on simulation-specific details"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Multiple Simulations"}),": Train across different simulation environments"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Validation During Training"}),": Continuously validate on simplified real-world tasks"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"deployment-phase",children:"Deployment Phase"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Gradual Deployment"}),": Start with simple tasks and increase complexity"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Safety First"}),": Implement multiple safety layers and emergency stops"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Monitoring"}),": Continuously monitor performance and detect failures"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Adaptation"}),": Implement online adaptation mechanisms"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"continuous-improvement",children:"Continuous Improvement"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Data Collection"}),": Collect real-world data to improve simulation models"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Model Updates"}),": Regularly update simulation models based on real data"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Feedback Loop"}),": Create a feedback loop between real and simulation performance"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"A/B Testing"}),": Compare different approaches in both simulation and reality"]}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"Sim-to-real transfer remains one of the most challenging aspects of robotics, requiring careful consideration of modeling assumptions, training procedures, and validation approaches. Success often requires a combination of multiple techniques tailored to the specific application and robot platform."})]})}function c(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(m,{...n})}):m(n)}},8453:(n,e,a)=>{a.d(e,{R:()=>s,x:()=>o});var i=a(6540);const t={},r=i.createContext(t);function s(n){const e=i.useContext(r);return i.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function o(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:s(n.components),i.createElement(r.Provider,{value:e},n.children)}}}]);